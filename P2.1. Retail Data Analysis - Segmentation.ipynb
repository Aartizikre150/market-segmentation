{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69e593ec",
   "metadata": {},
   "source": [
    "**Objective:** To understand and gain insights from a retail dataset by performing various exploratory data analyses, data visualization, and data modelling.\n",
    "\n",
    "**Dataset Columns:**\n",
    "\n",
    "- **InvoiceNo:** Invoice number. A unique number per invoice.\n",
    "- **StockCode:** Product code. A unique number per product.\n",
    "- **Description:** Product description.\n",
    "- **Quantity:** The number of products sold per invoice.\n",
    "- **InvoiceDate:** The date and time of the invoice.\n",
    "- **UnitPrice:** The price of one unit of the product.\n",
    "- **CustomerID:** Customer identification number.\n",
    "- **Country:** The country where the customer resides.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be5c509",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing and Cleaning:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0d4484",
   "metadata": {},
   "source": [
    "1.1. Import necessary libraries and read the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c634427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('Sales_data.csv', encoding='ANSI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ebb2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8135c246",
   "metadata": {},
   "source": [
    "1.2. Display the top 10 rows of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d17927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc87eac",
   "metadata": {},
   "source": [
    "1.3. Check for missing values:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9815619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347081eb",
   "metadata": {},
   "source": [
    "1.4. Convert the InvoiceDate column to datetime format:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d38806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9efbf30",
   "metadata": {},
   "source": [
    "1.5. Add a new column 'TotalPrice' to the dataframe which is the product of 'UnitPrice' and 'Quantity':\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0457e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalPrice'] = df['UnitPrice'] * df['Quantity']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfaf538",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e33e5c",
   "metadata": {},
   "source": [
    "2.1. How many unique products are there in the dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02895386",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_products = df['StockCode'].nunique()\n",
    "print(unique_products)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c96b6d4",
   "metadata": {},
   "source": [
    "2.2. Which are the top 10 products (using StockCode) sold by quantity?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123571d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_products = df.groupby('StockCode').sum().sort_values(by='Quantity', ascending=False).head(10)\n",
    "print(top_products['Quantity'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b9e74d",
   "metadata": {},
   "source": [
    "2.3. How many unique customers are there in the dataset?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_customers = df['CustomerID'].nunique()\n",
    "print(unique_customers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e0f75",
   "metadata": {},
   "source": [
    "2.4. Which country has the maximum number of unique customers?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b788eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_country = df.groupby('Country')['CustomerID'].nunique().idxmax()\n",
    "print(top_country)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc356316",
   "metadata": {},
   "source": [
    "2.5. Visualize the distribution of 'TotalPrice' using a histogram.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f49f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['TotalPrice'], bins=50, range=(df['TotalPrice'].min(), df['TotalPrice'].max()))\n",
    "plt.xlabel('Total Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Total Price')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f535b887",
   "metadata": {},
   "source": [
    "## 3. Data Aggregation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fdb78c",
   "metadata": {},
   "source": [
    "3.1. Compute the total sales (TotalPrice) per country.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b624d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_per_country = df.groupby('Country').sum()['TotalPrice']\n",
    "print(sales_per_country)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afaf60f",
   "metadata": {},
   "source": [
    "3.2. Identify the month in which the sales were highest.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c990b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month'] = df['InvoiceDate'].dt.month\n",
    "month_sales = df.groupby('Month').sum()['TotalPrice']\n",
    "top_month = month_sales.idxmax()\n",
    "print(top_month)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a409f9",
   "metadata": {},
   "source": [
    "3.3. Compute the average unit price per product.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_price_per_product = df.groupby('StockCode').mean()['UnitPrice']\n",
    "print(avg_price_per_product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7569b06",
   "metadata": {},
   "source": [
    "3.4. Compute the total quantity sold per customer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f246ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity_per_customer = df.groupby('CustomerID').sum()['Quantity']\n",
    "print(quantity_per_customer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7066f2e2",
   "metadata": {},
   "source": [
    "## 4. Data Visualization:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69e475a",
   "metadata": {},
   "source": [
    "4.1. Create a bar chart showcasing the sales (TotalPrice) for each country.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_per_country.plot(kind='bar', figsize=(10, 6))\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Total Sales per Country')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d99b512",
   "metadata": {},
   "source": [
    "4.2. Plot a line graph to showcase the trend of sales over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a76628",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('InvoiceDate', inplace=True)\n",
    "df.resample('M').sum()['TotalPrice'].plot()\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Sales Trend Over Time')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d60870d",
   "metadata": {},
   "source": [
    "4.3. Use a scatter plot to visualize the relationship between UnitPrice and Quantity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50374322",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='UnitPrice', y='Quantity', data=df)\n",
    "plt.title('Relationship between UnitPrice and Quantity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac1231c",
   "metadata": {},
   "source": [
    "4.4. Plot a heatmap to display the correlation between numeric columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181852fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a454c0",
   "metadata": {},
   "source": [
    "## 5. Advanced Analysis:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa4315b",
   "metadata": {},
   "source": [
    "5.1. Identify potential outliers in the dataset for the Quantity and UnitPrice columns using appropriate visualization techniques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df['Quantity'])\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(df['UnitPrice'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625251f7",
   "metadata": {},
   "source": [
    "5.2. Segment customers based on their purchase history (Consider factors like total purchases, frequency of purchases, etc.).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639bc2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalSpent'] = df['Quantity'] * df['UnitPrice']\n",
    "customer_segment = df.groupby('CustomerID').agg({'TotalSpent': 'sum', 'InvoiceNo': 'nunique'})\n",
    "customer_segment.rename(columns={'InvoiceNo': 'NumPurchases'}, inplace=True)\n",
    "print(customer_segment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cf22cf",
   "metadata": {},
   "source": [
    "5.3. For the top 5 products (by quantity sold), visualize their monthly sales trend.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb41e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_products = df.groupby('StockCode').sum().nlargest(5, 'Quantity').index\n",
    "filtered_df = df[df['StockCode'].isin(top_5_products)]\n",
    "pivot_data = filtered_df.groupby(['Month', 'StockCode']).sum()['Quantity'].unstack()\n",
    "pivot_data.plot()\n",
    "plt.ylabel('Quantity Sold')\n",
    "plt.title('Monthly Sales Trend for Top 5 Products')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711370b6",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning Analysis with Retail Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bce6ec",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925558ca",
   "metadata": {},
   "source": [
    "6.1 Extract 'Year', 'Month', 'Day', and 'Hour' from the InvoiceDate and create separate columns for each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e44a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df['Year'] = df['InvoiceDate'].dt.year\n",
    "df['Month'] = df['InvoiceDate'].dt.month\n",
    "df['Day'] = df['InvoiceDate'].dt.day\n",
    "df['Hour'] = df['InvoiceDate'].dt.hour\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b9648a",
   "metadata": {},
   "source": [
    "6.2 Create a new column `'ReturnFlag'` where if `'Quantity'` is less than zero, it's 1, otherwise 0. This will indicate whether an item was returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350242a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ReturnFlag'] = df['Quantity'].apply(lambda x: 1 if x < 0 else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8205d375",
   "metadata": {},
   "source": [
    "## 7. Customer Segmentation using Clustering:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6b42c7",
   "metadata": {},
   "source": [
    "7.1. Create a matrix RFM (Recency, Frequency, Monetary) for each customer:\n",
    "- Recency: Number of days since the last purchase\n",
    "- Frequency: Number of purchases\n",
    "- Monetary: Total money spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Recency, Frequency and Monetary for each customer\n",
    "current_date = df['InvoiceDate'].max()\n",
    "\n",
    "rfm = df.groupby('CustomerID').agg({\n",
    "    'InvoiceDate': lambda x: (current_date - x.max()).days,  # Recency\n",
    "    'InvoiceNo': 'count',                                   # Frequency\n",
    "    'TotalPrice': 'sum'                                      # Monetary\n",
    "}).rename(columns={\n",
    "    'InvoiceDate': 'Recency',\n",
    "    'InvoiceNo': 'Frequency',\n",
    "    'TotalPrice': 'Monetary'\n",
    "})\n",
    "\n",
    "rfm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d919df35",
   "metadata": {},
   "source": [
    "7.2. Normalize the RFM matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122309d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "rfm_normalized = scaler.fit_transform(rfm)\n",
    "rfm_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f405b1e2",
   "metadata": {},
   "source": [
    "7.3. Use K-Means clustering to segment customers into different groups. Determine the optimal number of clusters using the Elbow method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77141082",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U threadpoolctl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c2142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Determine the optimal number of clusters\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
    "    kmeans.fit(rfm_normalized)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow method\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(1, 11), wcss, marker='o', linestyle='--')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('K-means clustering Elbow Method')\n",
    "plt.show()\n",
    "\n",
    "# Based on the elbow point, choose optimal clusters and run KMeans\n",
    "optimal_clusters = 3  # this can change based on your elbow plot\n",
    "kmeans = KMeans(n_clusters=optimal_clusters, init='k-means++', random_state=42)\n",
    "clusters = kmeans.fit_predict(rfm_normalized)\n",
    "\n",
    "rfm['Cluster'] = clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2cc12d",
   "metadata": {},
   "source": [
    "## 8. Predictive Analytics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde92ff",
   "metadata": {},
   "source": [
    "8.1. Can you predict if a customer will return an item? Use the 'ReturnFlag' as the target variable and build a classification model.\n",
    "\n",
    "- Split data into training and test sets.\n",
    "- Use features like 'UnitPrice', 'Quantity', etc.\n",
    "- Evaluate model accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f94fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "features = df[['UnitPrice', 'Quantity']]  # you can add more features\n",
    "target = df['ReturnFlag']\n",
    "\n",
    "for col in ['InvoiceDate', 'InvoiceNo','StockCode', 'Description', 'Country', 'CustomerID']:\n",
    "    if col in features.columns:  \n",
    "        del features[col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78347efb",
   "metadata": {},
   "source": [
    "8.2. Predict the `'TotalPrice'` for an invoice using regression models.\n",
    "- Consider relevant features and handle categorical ones appropriately (e.g., with one-hot encoding).\n",
    "- Split data, train the model, and evaluate its performance using metrics like MAE, RMSE, and R^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4863816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Assuming df has dummy variables for categorical columns\n",
    "features = df.drop(columns=['TotalPrice'])\n",
    "target = df['TotalPrice']\n",
    "for col in ['InvoiceDate', 'InvoiceNo','StockCode', 'Description', 'Country', 'CustomerID']:\n",
    "    if col in features.columns:  \n",
    "        del features[col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "predictions = reg.predict(X_test)\n",
    "\n",
    "print('RMSE:', mean_squared_error(y_test, predictions, squared=False))\n",
    "print('R^2:', r2_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979bbed3",
   "metadata": {},
   "source": [
    "## 9. Association Rule Mining:\n",
    "- 9.1 Identify frequently bought products together. Use the Apriori algorithm to extract meaningful association rules.\n",
    "- 9.2 Based on the rules, suggest product bundling strategies to the retail store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d2a0f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install mlxtend --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cf91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Creating a basket\n",
    "basket = (df.groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))\n",
    "\n",
    "# Convert the units to 1 hot encoded values\n",
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1\n",
    "\n",
    "basket_encoded = basket.applymap(encode_units)\n",
    "\n",
    "# Build frequent items\n",
    "frequent_itemsets = apriori(basket_encoded, min_support=0.03, use_colnames=True)\n",
    "\n",
    "# Association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94407ec3",
   "metadata": {},
   "source": [
    "# Advanced EDA Techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d8d022",
   "metadata": {},
   "source": [
    "11. Pareto Analysis (80/20 Rule):\n",
    "- Identify the 20% of the products that generate 80% of the revenue.\n",
    "- Conversely, identify the 20% of the customers responsible for 80% of the sales.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1696cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_percent_products = int(0.2 * len(df['StockCode'].unique()))\n",
    "top_products = df.groupby('StockCode').sum().nlargest(top_20_percent_products, 'TotalPrice')\n",
    "top_products['TotalPrice'].plot(kind='bar')\n",
    "\n",
    "top_20_percent_customers = int(0.2 * len(df['CustomerID'].unique()))\n",
    "top_customers = df.groupby('CustomerID').sum().nlargest(top_20_percent_customers, 'TotalPrice')\n",
    "top_customers['TotalPrice'].head(20).plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065878fc",
   "metadata": {},
   "source": [
    "14. Time-Series Anomalies:\n",
    "- Detect any anomalies or outliers in the sales data over time using rolling averages or other advanced methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35234a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RollingMean'] = df['TotalPrice'].rolling(window=5).mean()\n",
    "\n",
    "anomalies = df[df['TotalPrice'] > df['RollingMean'] + 1.96*df['TotalPrice'].std()]\n",
    "plt.plot(df['InvoiceDate'], df['TotalPrice'])\n",
    "plt.plot(anomalies['InvoiceDate'], anomalies['TotalPrice'], 'ro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48c3c78",
   "metadata": {},
   "source": [
    "# Advanced Modeling Techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3355bd5f",
   "metadata": {},
   "source": [
    "15. Market Basket Analysis Enhancements:\n",
    "- Dig deeper into association rules. For instance, find rules with a high lift and high confidence.\n",
    "- Analyze antecedents with more than one item, which can give bundled product suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec784f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.1)\n",
    "top_rules = rules[rules['confidence'] > 0.01]\n",
    "sns.scatterplot(x='support', y='confidence', size='lift', data=top_rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cdf266",
   "metadata": {},
   "source": [
    "## 19. Product Recommendation Systems:\n",
    "- Develop a system to recommend products to users.\n",
    "- Consider collaborative filtering techniques, matrix factorization, or deep learning-based approaches like neural collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00cb1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Create a user-product matrix\n",
    "user_product_matrix = df.pivot_table(index='CustomerID', columns='StockCode', values='Quantity', fill_value=0)\n",
    "reindexed_user_product_matrix = user_product_matrix.reset_index()\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(user_product_matrix)\n",
    "\n",
    "# Get product recommendations for a user based on their purchase history\n",
    "def get_recommendations(user_id, cosine_sim=cosine_sim):\n",
    "    idx = reindexed_user_product_matrix[reindexed_user_product_matrix['CustomerID']==user_id].index[0]        \n",
    "    # Get pairwise similarity scores\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    \n",
    "    # Sort users based on similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get products bought by the most similar user\n",
    "    user_idx = sim_scores[1][0]\n",
    "    similar_user_products = user_product_matrix.iloc[user_idx]\n",
    "    recommended_products = similar_user_products[similar_user_products > 0].index.tolist()\n",
    "    \n",
    "    return recommended_products\n",
    "\n",
    "stockcodelist = get_recommendations(13113.0) # Replace 2154 with an actual CustomerID\n",
    "print(f\"Stockcode list for recommended products are - {stockcodelist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf20acd",
   "metadata": {},
   "source": [
    "## 20. Churn Prediction:\n",
    "- Predict if a customer will stop buying products in the near future.\n",
    "- Features can include Recency, Frequency, Monetary values, average time between purchases, total categories bought, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d03733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# For this example, let's assume if a customer hasn't purchased in the last 6 months, they've churned\n",
    "df['LastPurchase'] = df.groupby('CustomerID')['InvoiceDate'].transform('max')\n",
    "max_date = df['InvoiceDate'].max()\n",
    "df['Churn'] = (max_date - df['LastPurchase']).dt.days > 180\n",
    "\n",
    "X = df[['TotalPrice', 'Quantity']] # Add more relevant features\n",
    "y = df['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fc4e0f",
   "metadata": {},
   "source": [
    "## 21. Hyperparameter Tuning and Model Optimization:\n",
    "- For any given machine learning model you use, apply techniques like grid search or random search for hyperparameter tuning.\n",
    "- Use ensemble methods (e.g., stacking, bagging, boosting) to enhance prediction performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cb376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, verbose=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "grid_predictions = grid.predict(X_test)\n",
    "print(classification_report(y_test, grid_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
